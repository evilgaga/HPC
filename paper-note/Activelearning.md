## **研究目标**

探索主动学习在 DNN 代理模型训练中的应用潜力，并开发支持智能生成模拟数据的高性能计算基础设施，以提高科学模拟的效率和效果。

## 背景

- **高性能科学模拟的挑战**: 随着模拟模型复杂性的增加，其计算需求也随之提升，导致了资源限制和效率低下的问题。
- **DNN 代理模型的潜力**: 深度神经网络 (DNN) 作为代理模型，能够显著加速昂贵的科学模拟，例如分子动力学模拟、量子化学计算、气候模拟等。DNN 代理模型可以替代模拟中的某些内部组件或整个模拟，从而提高模拟效率。
- **现有 DNN 代理模型训练方法的局限性**: 现有的 DNN 代理模型训练方法通常需要大量覆盖输入参数空间的模拟数据，而这些数据的生成既昂贵又耗时。
- **主动学习**: 一种智能选择训练数据的方法，可以在没有大量预先标注数据的情况下，通过少量数据查询标签来实现 DNN 的高性能。将主动学习应用于 DNN 代理模型训练，可以实现智能探索参数空间和选择性地执行模拟运行，从而降低生成大量模拟数据的资源挑战，并减少 DNN 代理模型对预定义训练模拟的依赖。



## 相关工作

- **扩散求解器**: 扩散求解器是科学计算的重要组成部分，因为扩散过程在各种领域中普遍存在。传统的数值方法（如有限元法和有限差分法）在特定情况下表现出良好的鲁棒性和效率，但在更复杂的场景中受到限制。DNN 作为代理模型，为加速这些模拟提供了新的可能性，但也面临着**训练时间长、数据稀缺和缺乏物理原理集成**等挑战。
  - **数据生成**: 数据来自生物多尺度建模，对应于具有衰减率的二维网格上的两个源。数据集包含 20k 个初始配置，每个配置随机放置两个源，其中一个源的通量为 1，另一个源的通量在 0 到 1 之间随机分配。使用 Julia 中的 Differential Equation 包计算每个初始配置的稳态扩散场，并使用图像表示初始条件和预测的稳态解。
  - DNN 代理模型：考虑了两种 DNN 架构：
    - **CNN 自动编码器**: 由六个卷积层和六个反卷积层组成，分别用于特征提取和特征重建。
    - **U-Net**: 由四个最大池化层和四个反卷积层组成，并在编码器和解码器之间进行图像拼接，以捕获上下文信息。
  - **损失函数**: 为了避免源像素的权重过大，使用加权均方误差 (MAE) 作为损失函数，其中源像素的误差被赋予更大的权重。
- **深度主动学习 (DAL)**: 主动学习是一种增量智能选择数据的方法，旨在以较低的标注成本实现模型的高性能。DAL 是主动学习在深度学习领域的应用，已经开发出各种数据选择策略，包括基于不确定性和多样性的方法。**然而，这些方法大多针对图像分类任务，在科学模拟 DNN 代理模型构建中的应用研究较少**。
- **代理模型中的主动学习**: 一些研究开始探索主动学习在 DNN 代理模型构建中的应用。例如，使用贝叶斯主动学习来选择训练模拟，以加速神经网络代理模型的学习；使用基于误差度量的集成训练获取函数来减少光学表面组件的 DNN 代理模型所需的模拟次数；构建 DNN 代理模型来解决 PDE 约束优化问题，并使用 DNN 代理模型的优化目标函数作为获取函数；开发 ADEPT 框架来训练陀螺动力学湍流的代理模型，以最小化所需数据量。这些研究中的主动学习方法都是针对特定应用和 DNN 架构的，并且获取函数的设计还依赖于科学模拟的具体优化目标。

## difficulties and solution

**1. DNN 代理模型训练数据成本高**:

- **问题**: 现有的 DNN 代理模型训练方法依赖于大量的模拟数据，这些数据是启发式选择的，并且需要昂贵的计算生成。
- **解决方案**: 将主动学习纳入 DNN 代理模型训练，允许智能且客观地选择训练模拟，从而减少生成大量模拟数据的需要。

**2. DNN 代理模型性能依赖预先定义的训练模拟**:

- **问题**: 训练数据可能包含参数空间中某些区域的冗余子集，而在其他区域则不足，这会导致 DNN 代理模型的性能依赖于预先定义的训练模拟。
- **解决方案**: 主动学习可以根据模型的不确定性和数据多样性选择训练模拟，从而减少对预先定义训练模拟的依赖。

**3. DNN 架构选择的影响**:

- **问题**: DNN 架构的选择对主动学习的性能有显著影响。
- **解决方案**: 在进行主动学习之前，需要识别合适的 DNN 架构，以确保主动学习能够发挥其优势。

**4. 主动学习策略选择的影响**:

- **问题**: 目前尚不清楚哪种数据选择策略更适合 DNN 代理模型的建设。
- **解决方案**: 探索不同的主动学习策略，例如基于不确定性和多样性的策略，并评估其有效性。

## **方法**

**扩散求解器的 DNN 代理模型的主动学习**

- **主动学习过程**
  1. 初始训练：使用少量已标记的数据 (L) 训练 DNN 代理模型。
  2. 获取函数评估：使用获取函数评估未标记数据 (U) 中的每个样本，并选择最有信息量的样本。
  3. 标记和更新：将选定的样本标记并添加到 L 中，更新 DNN 代理模型。
  4. 重复：重复步骤 2-3，直到达到性能指标或标记数据量达到上限。
- **获取函数**
  - **熵**: 选择模型最不确定的样本，即输出预测的标准差最大的样本。
  - **时间输出差异 (TOD)**: 使用模型在不同学习迭代步骤上对同一样本的输出差异来估计模型损失，并选择损失最大的样本。
  - **参数多样性**: 基于生成模拟的参数的多样性来选择样本，即选择与已标记数据集距离最远的样本。
- **评估指标**: 本研究使用加权 MAE 和区域兴趣 MAE 来评估 DNN 代理模型的性能。加权 MAE 衡量模型预测与真实值之间的误差，区域兴趣 MAE 则分析不同区域（如源区域和场区域）的误差。

## **实验**

- **数据集**: 将 20k 个扩散数据集划分为 16,000 个训练数据、4,000 个验证数据和 4,000 个测试数据。
- **DNN 架构**: 使用 U-Net 和 CNN 自动编码器两种架构进行实验。
- **主动学习实验设置**
  - 将 16,000 个训练数据划分为 1,000 个初始标记数据和 15,000 个未标记数据池。
  - 使用三种获取函数 (熵、TOD 和参数多样性) 和随机获取进行实验。
  - 每个主动学习轮次中，选择 B 个未标记样本进行标注，并使用当前标记数据集重新训练 DNN 代理模型。
  - 重复主动学习过程，直到所有未标记样本都被标注。
  - 使用加权 MAE 和区域兴趣 MAE 评估 DNN 代理模型的性能。
- **实验结果**
  - **获取函数的比较**: TOD 获取函数在 U-Net 架构上表现最佳，能够使用更少的训练数据实现与随机获取相当的模型性能。熵获取函数次之，参数多样性获取函数的表现与随机获取相当或略好。
  - **架构对主动学习的影响**: U-Net 架构比 CNN 自动编码器更适合主动学习，能够更好地利用主动学习带来的性能提升。
  - **区域兴趣 MAE 的分析**: TOD 获取函数在源区域和场区域的预测误差始终低于随机获取，表明主动学习能够有效地提高模型在这些关键区域的预测精度。

![image-20241112185205877](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20241112185205877.png)

## 未来发展

**1. 扩展应用范围和数据集规模**

将研究范围扩展到更多科学模拟领域，例如流体力学、量子力学等。

**2. 探索更广泛的主动学习策略**

**3. 深入研究架构选择的影响**:

对更大规模的架构空间进行实证研究，并探索架构优化和网络架构搜索等技术，以找到更适合主动学习的 DNN 架构。

**4. 实现“智能代理”**:

开发高性能计算 (HPC) 基础设施，支持实时生成模拟数据，并根据主动学习策略进行数据采集和 DNN 代理模型训练，从而实现“智能代理”。

## 涉及的概念

### DNN的两种架构

**U-Net 架构**:

用于医学图像分割任务，但也被用于解决偏微分方程 (PDE) 问题。
- **结构特点**
  - **编码器**: 由卷积层组成，逐步减少图像的空间维度（宽度和高度），同时增加通道数，提取特征信息。
  - **瓶颈层**: 通常具有较小的空间维度和较高的通道数，包含最重要的特征信息。
  - **解码器**: 与编码器对称，逐步增加图像的空间维度，并减少通道数，最终恢复到原始图像尺寸，并将特征信息融合回像素级别。
  - **跳跃连接**: 编码器和解码器之间的跳跃连接将编码器中提取的特征信息直接传递给解码器，有助于更精确地重建图像。

**CNN 自动编码架构**:

用于图像压缩和去噪等任务。
- **结构特点**
  - **编码器**: 与 U-Net 编码器类似，通过卷积层逐步减少图像的空间维度并增加通道数。
  - **解码器**: 与 U-Net 解码器类似，通过反卷积层逐步增加图像的空间维度并减少通道数，最终恢复到原始图像尺寸。
  - **没有跳跃连接**: 与 U-Net 不同，CNN 自动编码器没有跳跃连接，这意味着编码器中提取的特征信息不会直接传递给解码器。

**两种架构的比较**:

- **U-Net** 通常在 PDE 问题的求解中表现更好，因为它能够更有效地融合编码器和解码器之间的特征信息。
- **CNN 自动编码器** 在图像压缩和去噪等任务中表现更好，因为它能够更有效地提取和重建图像的特征信息。
